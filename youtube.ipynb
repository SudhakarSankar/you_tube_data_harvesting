{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pymongo\n",
    "#from pymongo import MongoClient\n",
    "import psycopg2\n",
    "import pandas as pd \n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API Key Connection\n",
    "\n",
    "def APi_connect():\n",
    "    Api_ID = \"AIzaSyDKxTXNk8yWjLkDLpqLesZatoMmufOstao\"\n",
    "    api_service_name = \"youtube\"\n",
    "    api_version = \"v3\"\n",
    "    \n",
    "    youtube = build(api_service_name, api_version, developerKey=Api_ID)\n",
    "    \n",
    "    return youtube\n",
    "youtube = APi_connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Channel information\n",
    "\n",
    "def Get_channel_info(Channel_id):\n",
    "    request = youtube.channels().list(\n",
    "        part = \"snippet, contentDetails, statistics\",\n",
    "        id = Channel_id\n",
    "    )               \n",
    "    response = request.execute()\n",
    "\n",
    "    for item in response[\"items\"]:\n",
    "        Data = dict(Channel_name = item[\"snippet\"][\"title\"],\n",
    "                    Channel_id = item[\"id\"],\n",
    "                    Channel_description = item[\"snippet\"][\"description\"],\n",
    "                    Channel_subscriber_count = item[\"statistics\"][\"subscriberCount\"],\n",
    "                    Channel_playlist_id = item[\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"],\n",
    "                    Channel_views_count = item[\"statistics\"][\"viewCount\"],\n",
    "                    Channel_video_count = item[\"statistics\"][\"videoCount\"])\n",
    "    return Data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Channel_name': 'Data Science Tamil',\n",
       " 'Channel_id': 'UCuI5XcJYynHa5k_lqDzAgwQ',\n",
       " 'Channel_description': 'If you\\'re looking for more projects or need assistance completing one (with explanation or without explanation), feel free to contact me at datasciencetamil15502@gmail.com.\\n\\nWelcome to the Data Science Tamil Channel! Here, we delve into the captivating realm of data science, machine learning, and artificial intelligence.\\n\\nJoin us as we unravel the mysteries of data analysis, predictive modeling, and data visualization. From beginner-friendly tutorials to advanced discussions, we\\'ve got you covered.\\nStay tuned for regular updates, insightful discussions, and community interactions. Subscribe now and embark on an enlightening journey through the fascinating world of data science! üåê Let\\'s unlock the power of data together! üí™\\n\\n\"To all my subscribers: I want to reassure you that if there are any mistakes in my videos, I\\'ll annotate and guide for clarity. Your support fuels our content. Thank you!\"\\n',\n",
       " 'Channel_subscriber_count': '1330',\n",
       " 'Channel_playlist_id': 'UUuI5XcJYynHa5k_lqDzAgwQ',\n",
       " 'Channel_views_count': '205043',\n",
       " 'Channel_video_count': '85'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(Data)\n",
    "\n",
    "Channel_details = Get_channel_info(\"UCuI5XcJYynHa5k_lqDzAgwQ\")\n",
    "Channel_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get video ids\n",
    "\n",
    "def Get_video_ids(Channel_id):\n",
    "    video_ids = []\n",
    "    response = youtube.channels().list(id = Channel_id,\n",
    "                                    part = \"contentDetails\").execute()\n",
    "    playlist_id = response[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
    "\n",
    "    next_page_token = None  \n",
    "\n",
    "    while True:\n",
    "        response1 = youtube.playlistItems().list(part = [\"snippet\"],\n",
    "                                                playlistId = playlist_id,\n",
    "                                                maxResults = 50,\n",
    "                                                pageToken = next_page_token).execute()\n",
    "        for video_id in range(len(response1[\"items\"])):\n",
    "            video_ids.append(response1[\"items\"][video_id][\"snippet\"][\"resourceId\"][\"videoId\"])\n",
    "        next_page_token = response1.get(\"nextPageToken\")\n",
    "        \n",
    "        if next_page_token is None:\n",
    "            break\n",
    "    return video_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_ids_list = Get_video_ids(\"UCuI5XcJYynHa5k_lqDzAgwQ\") \n",
    "len(video_ids_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Video Information \n",
    "\n",
    "def get_video_info(video_ids_list):\n",
    "     video_data = []\n",
    "     for video_id in video_ids_list:\n",
    "          request = youtube.videos().list(\n",
    "               part = \"contentDetails, snippet, statistics\",\n",
    "               id = video_id\n",
    "          )\n",
    "          response = request.execute()\n",
    "          \n",
    "          for item in response[\"items\"]:\n",
    "               data = dict(channel_Title = item['snippet']['channelTitle'],\n",
    "                         channel_ID = item['snippet']['channelId'],\n",
    "                         video_ID = item['id'],\n",
    "                         title = item['snippet']['title'],\n",
    "                         tags = item['snippet'].get('tags'),   \n",
    "                         thumbnails = item['snippet']['thumbnails']['default']['url'],\n",
    "                         description = item['snippet']['description'],\n",
    "                         published_At = item['snippet']['publishedAt'],\n",
    "                         duration = item['contentDetails']['duration'],\n",
    "                         view_Count = item['statistics'].get('viewCount'),\n",
    "                         comment_Count = item['statistics'].get('commentCount'),\n",
    "                         like_Count = item['statistics'].get('likeCount'),\n",
    "                         favorite_Count = item['statistics']['favoriteCount'],\n",
    "                         definition = item['contentDetails']['definition'],\n",
    "                         caption = item['contentDetails']['caption'] \n",
    "                         )\n",
    "               video_data.append(data)\n",
    "     return video_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_Details = get_video_info(video_ids_list)\n",
    "len(video_Details)\n",
    "# video_Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get comments information\n",
    "\n",
    "def Get_Comment_Info(video_ids_list):\n",
    "    commend_Data = []\n",
    "    try:\n",
    "        for video_id in video_ids_list:\n",
    "            request = youtube.commentThreads().list(\n",
    "                part = 'snippet',\n",
    "                videoId = video_id,\n",
    "                maxResults = 50   \n",
    "            )\n",
    "            response = request.execute()\n",
    "\n",
    "            for item in response['items']:\n",
    "                data = dict(comment_Id = item['snippet']['topLevelComment']['id'],\n",
    "                            video_Id = item['snippet']['videoId'],\n",
    "                            comment_Text = item['snippet']['topLevelComment']['snippet']['textDisplay'],\n",
    "                            comment_Author = item['snippet']['topLevelComment']['snippet']['authorDisplayName'],\n",
    "                            comment_Published = item['snippet']['topLevelComment']['snippet']['publishedAt']\n",
    "                )\n",
    "                commend_Data.append(data)\n",
    "    except:\n",
    "        pass\n",
    "    return commend_Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_Details = Get_Comment_Info(video_ids_list)\n",
    "len(comment_Details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Playlist Information   \n",
    "\n",
    "def Get_Playlist_Detail(Channel_id):\n",
    "    next_Page_Token = None  \n",
    "    playlist_info = []\n",
    "    while True:\n",
    "        request = youtube.playlists().list(\n",
    "            part = \"snippet, contentDetails\",\n",
    "            channelId = Channel_id,\n",
    "            maxResults = 50,\n",
    "            pageToken = next_Page_Token      \n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            data = dict(playlist_Id = item['id'],\n",
    "                        title = item['snippet']['title'],\n",
    "                        Channel_Id = item['snippet']['channelId'],\n",
    "                        channel_Name = item['snippet']['channelTitle'],\n",
    "                        published_At = item['snippet']['publishedAt'],    \n",
    "                        item_Count = item['contentDetails']['itemCount']   \n",
    "            )\n",
    "            playlist_info.append(data)\n",
    "            \n",
    "        next_Page_Token = response.get('pageToken')\n",
    "        if next_Page_Token is None:\n",
    "            break\n",
    "        \n",
    "    return playlist_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_Detail = Get_Playlist_Detail('UCuI5XcJYynHa5k_lqDzAgwQ')\n",
    "#playlist_Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make connection in Mongo DB\n",
    "\n",
    "mongo_client = pymongo.MongoClient(\"mongodb+srv://sudhakarsankar:sudhakar@cluster0.9udq9e7.mongodb.net/?retryWrites=true&w=majority\")\n",
    "mongo_db = mongo_client[\"youtube_data\"]   \n",
    "#mongo_collection = mongo_db['channel_Details'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make connection in Mongo DB\n",
    "\n",
    "mongo_client = pymongo.MongoClient(\"mongodb+srv://sudhakarsankar:sudhakar@cluster0.9udq9e7.mongodb.net/\")\n",
    "mongo_db = mongo_client[\"youtube_data\"]   \n",
    "#mongo_collection = mongo_db['channel_Details'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_Details(channel_Id):\n",
    "    cha_Details = Get_channel_info(channel_Id)\n",
    "    Play_List_Details = Get_Playlist_Detail(channel_Id)\n",
    "    video_Id_List = Get_video_ids(channel_Id)\n",
    "    video_Details = get_video_info(video_Id_List)\n",
    "    com_Details = Get_Comment_Info(video_Id_List)\n",
    "    \n",
    "    mongo_collection.insert_one({\"channel_Information\" : cha_Details, \"Play_List_Information\" : Play_List_Details,\n",
    "                          \"video_Information\" : video_Details, \"comment_Information\" : com_Details})\n",
    "    \n",
    "    return \"Details uploaded successfully\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You tube channel ID\n",
    "\n",
    "#   UChGd9JY4yMegY6PxqpBjpRA   cience With Sam - ‡ÆÖ‡Æ±‡Æø‡Æµ‡Æø‡ÆØ‡Æ≤‡Øç ‡ÆÖ‡Æ±‡Æø‡Æµ‡Øã‡ÆÆ‡Øç\n",
    "#   UCy1lBBbXhtfzugF_LK2b6Yw   Tamil Business broadcast\n",
    "#   UCuI5XcJYynHa5k_lqDzAgwQ   DS Tutorial\n",
    "\n",
    "#   UCANClrNd5wRjJvQHVlCS4zQ   Vijay fort\n",
    "#   UCY6KjrDBN_tIRFT_QNqQbRQ   Madan Gowri\n",
    "#   UCJcCB-QYPIBcbKcBQOTwhiA   VJ Siddu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mongo_Db_Insert = channel_Details(\"UCuI5XcJYynHa5k_lqDzAgwQ\")  \n",
    "# mongo_Db_Insert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel Table creation in postgres SQL\n",
    "\n",
    "def channel_Table():\n",
    "    postgres_conn = psycopg2.connect(host ='localhost',\n",
    "                                        user ='postgres',\n",
    "                                        password ='sudhakar',\n",
    "                                        dbname ='youtube_data',\n",
    "                                        port = 5432)\n",
    "    postgres_cursor = postgres_conn.cursor()\n",
    "\n",
    "    drop_query = '''DROP TABLE IF EXISTS channels'''\n",
    "    postgres_cursor.execute(drop_query)\n",
    "    postgres_conn.commit()\n",
    "\n",
    "    try:\n",
    "        create_query = ''' CREATE TABLE if not exists channels (Channel_name VARCHAR(100),\n",
    "                                                                Channel_id VARCHAR(50) PRIMARY KEY,\n",
    "                                                                Channel_description TEXT,\n",
    "                                                                Channel_subscriber_count BIGINT,\n",
    "                                                                Channel_playlist_id VARCHAR(50),\n",
    "                                                                Channel_views_count BIGINT,\n",
    "                                                                Channel_video_count INT)'''\n",
    "\n",
    "        postgres_cursor.execute(create_query)\n",
    "        postgres_conn.commit()\n",
    "        print(\"Channel table created\")\n",
    "        \n",
    "    except:\n",
    "        print(\"Channel table already created\")\n",
    "        \n",
    "        \n",
    "    cha_List = []\n",
    "    mongo_db = mongo_client[\"youtube_data\"]   \n",
    "    mongo_collection = mongo_db['channel_Details'] \n",
    "    for cha_Data in mongo_collection.find({}, {\"_id\":0, \"channel_Information\":1}):\n",
    "        cha_List.append(cha_Data['channel_Information'])\n",
    "    df = pd.DataFrame(cha_List)\n",
    "\n",
    "\n",
    "        \n",
    "    try:\n",
    "    # Sample DataFrame 'df' assumed to exist\n",
    "        for index, row in df.iterrows():\n",
    "            insert_query = ''' INSERT INTO channels ( Channel_name,\n",
    "                                                        Channel_id,\n",
    "                                                        Channel_description,\n",
    "                                                        Channel_subscriber_count,\n",
    "                                                        Channel_playlist_id,\n",
    "                                                        Channel_views_count,\n",
    "                                                        Channel_video_count)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s) '''\n",
    "            \n",
    "            values = (row['Channel_name'],\n",
    "                        row['Channel_id'],\n",
    "                        row['Channel_description'],\n",
    "                        row['Channel_subscriber_count'],\n",
    "                        row['Channel_playlist_id'],\n",
    "                        row['Channel_views_count'],\n",
    "                        row['Channel_video_count'])\n",
    "            \n",
    "            # Execute the query and commit for each row\n",
    "            \n",
    "            postgres_cursor.execute(insert_query, values)\n",
    "            postgres_conn.commit()\n",
    "\n",
    "        print(\"Table values are inserted\")\n",
    "\n",
    "    except:\n",
    "        print(f\"Table values are already inserted\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playlists Table creation in postgres SQL\n",
    "\n",
    "def playlist_Table():\n",
    "    postgres_conn = psycopg2.connect(host='localhost',\n",
    "                                        user='postgres',\n",
    "                                        password='sudhakar',\n",
    "                                        dbname='youtube_data',\n",
    "                                        port=5432)\n",
    "    postgres_cursor = postgres_conn.cursor()\n",
    "\n",
    "    drop_query = '''DROP TABLE IF EXISTS playlists'''\n",
    "    postgres_cursor.execute(drop_query)\n",
    "    postgres_conn.commit()\n",
    "\n",
    "    create_query = '''CREATE TABLE if not exists playlists (playlist_Id VARCHAR(60) PRIMARY KEY,\n",
    "                                                            title VARCHAR(100),\n",
    "                                                            Channel_Id VARCHAR(60),\n",
    "                                                            channel_Name VARCHAR(100),\n",
    "                                                            published_At VARCHAR(100),\n",
    "                                                            item_Count INT)'''\n",
    "    postgres_cursor.execute(create_query)\n",
    "    postgres_conn.commit()\n",
    "\n",
    "\n",
    "    play_List = []\n",
    "    mongo_db = mongo_client[\"youtube_data\"]\n",
    "    mongo_collection = mongo_db[\"channel_Details\"]\n",
    "    for playlist_Data in mongo_collection.find({}, {\"_id\":0, \"Play_List_Information\":1}):  # channel count\n",
    "        for i in range(len(playlist_Data[\"Play_List_Information\"])):\n",
    "            play_List.append(playlist_Data['Play_List_Information'][i])\n",
    "    df1 = pd.DataFrame(play_List)\n",
    "\n",
    "\n",
    "\n",
    "    for index, row in df1.iterrows():\n",
    "        insert_query = '''INSERT INTO playlists (playlist_Id,\n",
    "                                                    title,\n",
    "                                                    Channel_Id,\n",
    "                                                    channel_Name,\n",
    "                                                    published_At,\n",
    "                                                    item_Count)\n",
    "                        VALUES (%s, %s, %s, %s, %s, %s)'''\n",
    "\n",
    "        values = (row['playlist_Id'],\n",
    "                    row['title'],\n",
    "                    row['Channel_Id'],\n",
    "                    row['channel_Name'],\n",
    "                    row['published_At'],\n",
    "                    row['item_Count'])\n",
    "\n",
    "        postgres_cursor.execute(insert_query, values)\n",
    "        postgres_conn.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# videos Table creation in SQL Server\n",
    "\n",
    "def videos_Table():\n",
    "    postgres_conn = psycopg2.connect(host='localhost',\n",
    "                                        user='postgres',\n",
    "                                        password='sudhakar',\n",
    "                                        dbname='youtube_data',\n",
    "                                        port=5432)\n",
    "    postgres_cursor = postgres_conn.cursor()\n",
    "\n",
    "    drop_query = '''DROP TABLE IF EXISTS videos'''\n",
    "    postgres_cursor.execute(drop_query)\n",
    "    postgres_conn.commit()\n",
    "\n",
    "    create_query = '''CREATE TABLE if not exists videos (channel_Title varchar(200),\n",
    "                                                            channel_ID varchar(200),\n",
    "                                                            video_ID varchar(100) primary key,\n",
    "                                                            title varchar(300),\n",
    "                                                            tags text,   \n",
    "                                                            thumbnails varchar(200),\n",
    "                                                            description text,\n",
    "                                                            published_At timestamp,\n",
    "                                                            duration interval,\n",
    "                                                            view_Count bigint,\n",
    "                                                            comment_Count int,\n",
    "                                                            like_Count int,\n",
    "                                                            favorite_Count int,\n",
    "                                                            definition varchar(200),\n",
    "                                                            caption varchar(300))'''\n",
    "    postgres_cursor.execute(create_query)\n",
    "    postgres_conn.commit()\n",
    "\n",
    "\n",
    "    video_List = []\n",
    "    mongo_db = mongo_client[\"youtube_data\"]\n",
    "    mongo_collection = mongo_db[\"channel_Details\"]\n",
    "    for video_Data in mongo_collection.find({}, {\"_id\":0, \"video_Information\":1}):  # channel count\n",
    "        for i in range(len(video_Data[\"video_Information\"])):\n",
    "            video_List.append(video_Data['video_Information'][i])\n",
    "    df2 = pd.DataFrame(video_List) \n",
    "\n",
    "\n",
    "    for index, row in df2.iterrows():\n",
    "        insert_query = '''INSERT INTO videos ( channel_Title,\n",
    "                                                    channel_ID,\n",
    "                                                    video_ID,\n",
    "                                                    title,\n",
    "                                                    tags,   \n",
    "                                                    thumbnails,\n",
    "                                                    description,\n",
    "                                                    published_At,\n",
    "                                                    duration,\n",
    "                                                    view_Count,\n",
    "                                                    comment_Count,\n",
    "                                                    like_Count,\n",
    "                                                    favorite_Count,\n",
    "                                                    definition,\n",
    "                                                    caption)\n",
    "        \n",
    "                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s,%s, %s, %s, %s, %s, %s, %s)'''\n",
    "\n",
    "        values = (row['channel_Title'],\n",
    "                    row['channel_ID'],\n",
    "                    row['video_ID'],\n",
    "                    row['title'],\n",
    "                    row['tags'],\n",
    "                    row['thumbnails'],\n",
    "                    row['description'],\n",
    "                    row['published_At'],\n",
    "                    row['duration'],\n",
    "                    row['view_Count'],\n",
    "                    row['comment_Count'],\n",
    "                    row['like_Count'],\n",
    "                    row['favorite_Count'],\n",
    "                    row['definition'],\n",
    "                    row['caption'])\n",
    "\n",
    "        postgres_cursor.execute(insert_query, values)\n",
    "        postgres_conn.commit()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    " # comments Table creation in postgres SQL\n",
    "\n",
    "def comments_Table():\n",
    "    postgres_conn = psycopg2.connect(host ='localhost',\n",
    "                                        user ='postgres',\n",
    "                                        password ='sudhakar',\n",
    "                                        dbname ='youtube_data',\n",
    "                                        port = 5432)\n",
    "    postgres_cursor = postgres_conn.cursor()\n",
    "\n",
    "    drop_query = '''DROP TABLE IF EXISTS comments'''\n",
    "    postgres_cursor.execute(drop_query)\n",
    "    postgres_conn.commit()\n",
    "\n",
    "    create_query = '''CREATE TABLE if not exists comments (comment_Id varchar(100) primary key,\n",
    "                                                            video_Id varchar(50),\n",
    "                                                            comment_Text text,\n",
    "                                                            comment_Author varchar(100),\n",
    "                                                            comment_Published timestamp)'''\n",
    "    postgres_cursor.execute(create_query)\n",
    "    postgres_conn.commit()\n",
    "\n",
    "\n",
    "    comment_List = []\n",
    "    mongo_db = mongo_client[\"youtube_data\"]\n",
    "    mongo_collection = mongo_db[\"channel_Details\"]\n",
    "    for comment_Data in mongo_collection.find({}, {\"_id\":0, \"comment_Information\":1}):  # channel count\n",
    "        for i in range(len(comment_Data[\"comment_Information\"])):\n",
    "            comment_List.append(comment_Data['comment_Information'][i])\n",
    "    df3 = pd.DataFrame(comment_List)\n",
    "\n",
    "\n",
    "    try:\n",
    "        for index, row in df3.iterrows():\n",
    "            insert_query = '''INSERT INTO comments (comment_Id, video_Id, comment_Text, comment_Author, comment_Published)\n",
    "                            VALUES (%s, %s, %s, %s, %s)'''\n",
    "\n",
    "            values = (row['comment_Id'], row['video_Id'], row['comment_Text'], row['comment_Author'], row['comment_Published'])\n",
    "\n",
    "            postgres_cursor.execute(insert_query, values)\n",
    "            postgres_conn.commit()\n",
    "\n",
    "        print(\"Data inserted successfully\")\n",
    "\n",
    "    except Exception as e:\n",
    "        postgres_conn.rollback()  # Rollback the transaction\n",
    "        print(\"Error occurred:\", e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tables():\n",
    "    channel_Table()\n",
    "    playlist_Table()\n",
    "    videos_Table()\n",
    "    comments_Table()\n",
    "    \n",
    "    return 'Tables created successfully'\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel table created\n",
      "Table values are inserted\n",
      "Data inserted successfully\n"
     ]
    }
   ],
   "source": [
    "tables = Tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_Channel_Table():\n",
    "    cha_List = []\n",
    "    mongo_db = mongo_client[\"youtube_data\"]   \n",
    "    mongo_collection = mongo_db['channel_Details'] \n",
    "    for cha_Data in mongo_collection.find({}, {\"_id\":0, \"channel_Information\":1}):\n",
    "        cha_List.append(cha_Data['channel_Information'])\n",
    "    df = st.dataframe(cha_List)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_Playlist_Table():\n",
    "    play_List = []\n",
    "    mongo_db = mongo_client[\"youtube_data\"]\n",
    "    mongo_collection = mongo_db[\"channel_Details\"]\n",
    "    for playlist_Data in mongo_collection.find({}, {\"_id\":0, \"Play_List_Information\":1}):  # channel count\n",
    "        for i in range(len(playlist_Data[\"Play_List_Information\"])):\n",
    "            play_List.append(playlist_Data['Play_List_Information'][i])\n",
    "    df1 = st.dataframe(play_List)\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_Video_Table():\n",
    "    video_List = []\n",
    "    mongo_db = mongo_client[\"youtube_data\"]\n",
    "    mongo_collection = mongo_db[\"channel_Details\"]\n",
    "    for video_Data in mongo_collection.find({}, {\"_id\":0, \"video_Information\":1}):  # channel count\n",
    "        for i in range(len(video_Data[\"video_Information\"])):\n",
    "            video_List.append(video_Data['video_Information'][i])\n",
    "    df2 = st.dataframe(video_List) \n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_Comment_Table():\n",
    "    comment_List = []\n",
    "    mongo_db = mongo_client[\"youtube_data\"]\n",
    "    mongo_collection = mongo_db[\"channel_Details\"]\n",
    "    for comment_Data in mongo_collection.find({}, {\"_id\":0, \"comment_Information\":1}):  # channel count\n",
    "        for i in range(len(comment_Data[\"comment_Information\"])):\n",
    "            comment_List.append(comment_Data['comment_Information'][i])\n",
    "    df3 = st.dataframe(comment_List)\n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 23:26:33.789 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.207 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\vsudh\\AppData\\Roaming\\Python\\Python313\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-03-05 23:26:34.207 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.208 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.209 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.210 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.210 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.211 Session state does not function when running a script without `streamlit run`\n",
      "2025-03-05 23:26:34.213 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.213 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.215 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.216 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.217 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.217 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.218 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.219 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.220 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.221 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.222 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.223 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.223 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.224 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.224 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.225 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.226 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.226 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.274 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.275 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Streamlit \n",
    "\n",
    "\n",
    "st.header(\":red[YOUTUBE DATA HARVESTING AND WAREHOUSING]\")\n",
    "\n",
    "channel_ID = st.text_input(\"Enter the channel ID\")\n",
    "\n",
    "if st.button(\"Store the data into MONGODB\"):\n",
    "    channel_ids = []\n",
    "    mongo_db = mongo_client['youtube_data']\n",
    "    mongo_collection = mongo_db['channel_Details']\n",
    "    for channel_data in mongo_collection.find({}, {'_id' : 0, 'channel_Information' : 1}):\n",
    "        channel_ids.append(channel_data['channel_Information']['Channel_id'])\n",
    "        \n",
    "    if channel_ID in channel_ids:\n",
    "        st.success('Channel ID already exist')\n",
    "        \n",
    "    else:\n",
    "        insert = channel_Details(channel_ID)\n",
    "        st.success(insert)\n",
    "        \n",
    "if st.button(\"Data Migrate to SQL\"):\n",
    "    SQL_Table = Tables()\n",
    "    st.success(SQL_Table)\n",
    "    \n",
    "    \n",
    "view_Table = st.radio(\"Select the table for view\", (\"CHANNEL\", \"PLAYLIST\", \"VIDEO\", \"COMMENT\"))\n",
    "\n",
    "if view_Table == \"CHANNEL\" :\n",
    "    view_Channel_Table()\n",
    "    \n",
    "elif view_Table == \"PLAYLIST\" :\n",
    "    view_Playlist_Table()\n",
    "    \n",
    "elif view_Table == \"VIDEO\" :\n",
    "    view_Video_Table()\n",
    "    \n",
    "elif view_Table == \"COMMENT\" :\n",
    "    view_Comment_Table()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 23:26:34.390 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.390 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.391 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.392 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.392 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.393 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.408 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.409 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# SQL Connection \n",
    "\n",
    "postgres_conn = psycopg2.connect(host ='localhost',\n",
    "                                        user ='postgres',\n",
    "                                        password ='sudhakar',\n",
    "                                        dbname ='youtube_data',\n",
    "                                        port = 5432)\n",
    "postgres_cursor = postgres_conn.cursor()\n",
    "\n",
    "question = st.selectbox(\"Select the question\", (\"1.\tWhat are the names of all the videos and their corresponding channels?\",\n",
    "                                                \"2.\tWhich channels have the most number of videos, and how many videos do they have?\",\n",
    "                                                \"3.\tWhat are the top 10 most viewed videos and their respective channels?\",\n",
    "                                                \"4.\tHow many comments were made on each video, and what are their corresponding video names?\",\n",
    "                                                \"5.\tWhich videos have the highest number of likes, and what are their corresponding channel names?\",\n",
    "                                                \"6.\tWhat is the total number of likes and dislikes for each video, and what are their corresponding video names?\",\n",
    "                                                \"7.\tWhat is the total number of views for each channel, and what are their corresponding channel names?\",\n",
    "                                                \"8.\tWhat are the names of all the channels that have published videos in the year 2022?\",\n",
    "                                                \"9.\tWhat is the average duration of all videos in each channel, and what are their corresponding channel names?\",\n",
    "                                                \"10. Which videos have the highest number of comments, and what are their corresponding channel names?\"))\n",
    "\n",
    "if question == \"1.\tWhat are the names of all the videos and their corresponding channels?\" :\n",
    "    query1 = '''select title as videos, channel_Title as channelName from videos'''\n",
    "    postgres_cursor.execute(query1)\n",
    "    postgres_conn.commit\n",
    "    query1_Data = postgres_cursor.fetchall()\n",
    "    df1 = pd.DataFrame(query1_Data, columns = ['video title', 'channel name'])\n",
    "    st.write(df1)\n",
    "    \n",
    "elif question == \"2.\tWhich channels have the most number of videos, and how many videos do they have?\" :\n",
    "    query2 = '''select Channel_name, Channel_video_count from channels\n",
    "                order by Channel_video_count desc'''\n",
    "    postgres_cursor.execute(query2)\n",
    "    postgres_conn.commit()\n",
    "    query2_Data = postgres_cursor.fetchall()\n",
    "    df2 = pd.DataFrame(query2_Data, columns = ['channel name', 'total videos'])\n",
    "    st.write(df2)\n",
    "    \n",
    "elif question == \"3.\tWhat are the top 10 most viewed videos and their respective channels?\" :\n",
    "    query3 = '''select view_Count, channel_Title, title from videos\n",
    "                where view_Count is not null order by view_Count desc limit 10'''\n",
    "    postgres_cursor.execute(query3)\n",
    "    postgres_conn.commit()\n",
    "    query3_Data = postgres_cursor.fetchall()\n",
    "    df3 = pd.DataFrame(query3_Data, columns = ['View count', 'Channel name', 'Video title'])\n",
    "    st.write(df3)\n",
    "    \n",
    "elif question == \"4.\tHow many comments were made on each video, and what are their corresponding video names?\" :\n",
    "    query4 = '''select comment_Count, title from videos\n",
    "                where comment_Count is not null'''\n",
    "    postgres_cursor.execute(query4)\n",
    "    postgres_conn.commit()\n",
    "    query4_Data = postgres_cursor.fetchall()\n",
    "    df4 = pd.DataFrame(query4_Data, columns = ['Comment count', 'Video title'])\n",
    "    st.write(df4)\n",
    "    \n",
    "elif question == \"5.\tWhich videos have the highest number of likes, and what are their corresponding channel names?\" :\n",
    "    query5 = '''select like_Count, title, channel_Title from videos\n",
    "                where like_Count is not null order by like_Count desc'''\n",
    "    postgres_cursor.execute(query5)\n",
    "    postgres_conn.commit()\n",
    "    query5_Data = postgres_cursor.fetchall()\n",
    "    df5 = pd.DataFrame(query5_Data, columns = ['Like count', 'Video title', 'Channel title'])\n",
    "    st.write(df5)\n",
    "    \n",
    "elif question == \"6.\tWhat is the total number of likes and dislikes for each video, and what are their corresponding video names?\" :\n",
    "    query6 = '''select like_Count, title from videos\n",
    "                where like_Count is not null order by like_Count desc'''\n",
    "    postgres_cursor.execute(query6)\n",
    "    postgres_conn.commit()\n",
    "    query6_Data = postgres_cursor.fetchall()\n",
    "    df6 = pd.DataFrame(query6_Data, columns = ['Like count', 'Video title name'])\n",
    "    st.write(df6)\n",
    "    \n",
    "elif question == \"7.\tWhat is the total number of views for each channel, and what are their corresponding channel names?\" :\n",
    "    query7 = '''select Channel_views_count, Channel_name from channels'''\n",
    "    postgres_cursor.execute(query7)\n",
    "    postgres_conn.commit()\n",
    "    query7_Data = postgres_cursor.fetchall()\n",
    "    df7 = pd.DataFrame(query7_Data, columns = ['Channel view count', 'Channel name'])\n",
    "    st.write(df7)\n",
    "    \n",
    "elif question == \"8.\tWhat are the names of all the channels that have published videos in the year 2022?\" :\n",
    "    query8 = '''select channel_Title, title, published_At from videos\n",
    "                where extract(year from published_At) = 2022'''\n",
    "    postgres_cursor.execute(query8)\n",
    "    postgres_conn.commit()\n",
    "    query8_Data = postgres_cursor.fetchall()\n",
    "    df8 = pd.DataFrame(query8_Data, columns = ['Channel title', 'Video title', 'Published date'])\n",
    "    st.write(df8)\n",
    "        \n",
    "elif question == \"9.\tWhat is the average duration of all videos in each channel, and what are their corresponding channel names?\" :\n",
    "    query9 = '''select channel_Title, AVG(duration) as averageDuration from videos\n",
    "                group by channel_Title'''\n",
    "    postgres_cursor.execute(query9)\n",
    "    postgres_conn.commit()\n",
    "    query9_Data = postgres_cursor.fetchall()\n",
    "    df9 = pd.DataFrame(query9_Data, columns = ['ChannelTitle', 'AverageDuration'])\n",
    "\n",
    "    # Average duration not displaying in streamlit so \n",
    "    query9_Data = []\n",
    "    for index, row in df9.iterrows():\n",
    "        cha_Title = row['ChannelTitle']\n",
    "        avg_Duration = row['AverageDuration']\n",
    "        avg_Duration_STR = str(avg_Duration)\n",
    "        query9_Data.append(dict(ChannelTitle = cha_Title, AverageDuration = avg_Duration_STR))\n",
    "    df = pd.DataFrame(query9_Data) \n",
    "    st.write(df)\n",
    "    \n",
    "elif question == \"10. Which videos have the highest number of comments, and what are their corresponding channel names?\" :\n",
    "    query10 = '''select channel_Title, title, comment_Count from videos\n",
    "                where comment_Count is not null order by comment_Count desc'''\n",
    "    postgres_cursor.execute(query10)\n",
    "    postgres_conn.commit()\n",
    "    query10_Data = postgres_cursor.fetchall()\n",
    "    df10 = pd.DataFrame(query10_Data, columns = ['Channel title', 'Video title', 'Comment count'])\n",
    "    st.write(df10)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 23:26:34.509 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-05 23:26:34.510 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "postgres_conn = psycopg2.connect(host ='localhost',\n",
    "                                        user ='postgres',\n",
    "                                        password ='sudhakar',   \n",
    "                                        dbname ='youtube_data',\n",
    "                                        port = 5432)\n",
    "postgres_cursor = postgres_conn.cursor()\n",
    "\n",
    "#elif question == \"10. Which videos have the highest number of comments, and what are their corresponding channel names?\" :\n",
    "query10 = '''select channel_Title, title, comment_Count from videos\n",
    "            where comment_Count is not null order by comment_Count desc'''\n",
    "postgres_cursor.execute(query10)\n",
    "postgres_conn.commit()\n",
    "query10_Data = postgres_cursor.fetchall()\n",
    "df10 = pd.DataFrame(query10_Data, columns = ['Channel title', 'Video title', 'Comment count'])\n",
    "st.write(df10)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel title</th>\n",
       "      <th>Video title</th>\n",
       "      <th>Comment count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Channel title, Video title, Comment count]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
